[{"title":"Java代码风格之常量","date":"2020-06-25T16:37:15.000Z","path":"posts/ddb1142c.html","text":"常量命名规范常量是作用域内保持不变的值。一般用final关键字修饰，根据作用域不同分为全局常量，类内常量，局部常量。 1.全局常量 指类的公开静态属性，使用public static final 修饰； 2.类内常量 指私有静态属性，使用private static final 修饰； 3.局部常量 分为方法常量和参数常量。前者是方法或代码块内定义的常量，后者是在定义形参时增加 final 标识，表示此参数值不能被修改。 下面是这些不同类型变量的示例： 12345678910public class Constant &#123; // 全局常量，类内常量：变量名称全大写，单词之间下划线分割 public static final String GLOBAL_CONSTANT = \"shared in global\"; private static final String CLASS_CONSTANT = \"shared in class\"; public void f (String a) &#123; // 局部常量：变量名称小驼峰 final String methodContant = \"shared in method\"; &#125;&#125; 禁用魔法值即共识层面上的常量，直接以具体的数值或字符出现在代码中。如下代码： 12String key = \"Id#taobao_\" + readeId;cache.put(key, value); 这段代码是保存信息到缓存中的方法，即使用魔法值组装key。如果在key拼接过程中错误的将&quot;Id#taobao_&quot;写成&quot;Id#taobao&quot;少了下划线，这就会导致缓存没有命中而去访问数据库，一般在测试环境数据量不大情况下并不容易发现这个问题的严重性，但是在大促时缓存失效导致数据库瞬间压力急剧上升，导致查询变慢。 所以，即使类内常量和局部常量只用一次，也应该赋予一个有意义的名称，保证后期使用时方便理解和值出同源。 参考《码出高效Java开发手册》","tags":[{"name":"Java","slug":"Java","permalink":"https://fuos.github.io/my-blog/tags/Java/"},{"name":"开发规范","slug":"开发规范","permalink":"https://fuos.github.io/my-blog/tags/%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83/"}]},{"title":"Hive DDL ROW FORMAT","date":"2020-06-17T05:38:22.000Z","path":"posts/acf44460.html","text":"DDL语法规则 CREATE DATABASE/SCHEMA, TABLE, VIEW, FUNCTION, INDEX（创建 数据库/模式，表，视图，函数，索引） DROP DATABASE/SCHEMA, TABLE, VIEW, INDEX（删除 数据库/模式，表，视图，索引） TRUNCATE TABLE（清空 表） ALTER DATABASE/SCHEMA, TABLE, VIEW（修改 数据库/模式，表，视图） MSCK REPAIR TABLE (or ALTER TABLE RECOVER PARTITIONS)（MSCK修复表或ALTER TABLE恢复分区） SHOW DATABASES/SCHEMAS, TABLES, TBLPROPERTIES, VIEWS, PARTITIONS, FUNCTIONS, INDEX[ES], COLUMNS, CREATE TABLE（查看） DESCRIBE DATABASE/SCHEMA, table_name, view_name（查看 数据库/模式描述信息） 创建表时需要指定数据切分格式，会用到ROW FORMAT关键字。可以参考Hive官网关于ROW FORMAT的用法。 下面通过一个例子说明数据之间分隔符用法。比如有两条数据： 121,Lilei,book-tv-code,beijing:chaoyang-shanghai:pudong2,Hanmeimei,book-Lilei-code,beijing:haidian-shanghai:huangpu 先看JAVA集合框架图，明确每个字段数据类型，再看数据格式，指定分隔符。 分隔符类型限定符开始语句———-ROW FORMAT DELIMITED 每个字段之间由[ , ]分割———-FIELDS TERMINATED BY ‘,’ 第二个字段是Array形式，元素与元素之间由[ - ]分割———-COLLECTION ITEMS TERMINATED BY ‘-‘ 第三个字段是K-V形式，每组K-V对内部由[ : ]分割，每组K-V对之间由[ - ]分割———-MAP KEYS TERMINATED BY ‘:’ 每条数据之间由换行符分割（默认[ \\n ]），如果是其它分割方式（比如[ ; ]）———-LINES TERMINATED BY ‘;’ 完整建表语句12345678910create table psn (id INT,name STRING,hobbies ARRAY &lt;STRING&gt;,address MAP &lt;STRING, STRING&gt;)ROW FORMAT DELIMITEDFIELDS TERMINATED BY ','COLLECTION ITEMS TERMINATED BY '-'MAP KEYS TERMINATED BY ':';","tags":[{"name":"Hive","slug":"Hive","permalink":"https://fuos.github.io/my-blog/tags/Hive/"}]},{"title":"PAI算法组件详解-PLDA","date":"2020-06-17T05:15:12.000Z","path":"posts/72ac77ba.html","text":"通过文章主题做文本分类的理论依据直观来讲，如果一篇文章有一个中心思想，那么一些特定词语会更频繁的出现。比方说，如果一篇文章是在讲猫的，那”猫”和”鱼”等词出现的频率会高些，如果一篇文章是在讲狗的，那”狗”和”骨头”等词出现的频率会高些。而有些词例如”这个”、”和”大概在两篇文章中出现的频率会大致相等。但真实的情况是，一篇文章通常包含多种主题，而且每个主题所占比例各不相同。因此，如果一篇文章10%和猫有关，90%和狗有关，那么和狗相关的关键字出现的次数大概会是和猫相关的关键字出现次数的9倍。 由于上面的理论基础，在文本分析中就有了基于文章主题的分类方法。 主题模型是用来在一系列文档中发现抽象主题（topic）的一种统计模型（在机器学习PAI平台，我们给PLDA组件设置topic参数值为50，表示让每篇文章抽象出50个主题）。 主题模型核心思想：数学框架（统计+概率）主题模型试图用数学框架来体现文档的这种特点。主题模型自动分析每个文档，统计文档内的词语，根据统计的信息来断定当前文档含有哪些主题，以及每个主题所占的比例各为多少。 下面说一种最经典的主题模型-LDA（隐含狄利克雷分布）LDA(Latent Dirichlet allocation)，是一种主题模型，它可以将[文档集]中每篇文档的主题按照概率分布的形式给出，从而通过分析一些文档抽取出它们的主题，然后根据主题给文本分类。它是一种无监督学习算法，在训练时不需要手工标注的训练集，需要的仅仅是文档集以及指定主题的数量k（这个K就是PLDA参数topic）即可。 目前机器学习PAI平台文本分析组件PLDA，它是Google对LDA的开源实现。语料生成过程（语料就是我们需要分析的所有文本，即文本集）假设语料库中有M篇文档（在这里我们定义：z是主题, w是词, d是文档），其中W(m)表示第m篇文档中的词，Z(m)表示这些词对应的topic编号。所有的word和对应的topic如下表示： 红色方框内即表示一篇文档是由若干个词组成的，每个词都对应一个主题。（就像一篇文章所有的词都是为了更好的表达主题而存在的） 下面我们思考当写一篇文章时你是怎么做的。假设你要写一篇文章，首先想好了主题（一个或多个），然后围绕这几个主题（比如”Arts””Budgets””Children””Education”）你会想到很多与之相关的词： 最后我们就是用这些和主题相关的词完成了一篇文章，就像下图一样，不同的颜色代表不同主题下的词，从颜色能看出每个主题的下面的词出现概率是不相同的： 上面的这个案例是我们在确定主题和词之后生成文章的步骤。然后伟大的数学家把这个过程抽象成了概率分布问题（关于如何抽象，当然是一大堆假设和公式推导，最后得出结论） 生成这篇文章可以看作如下过程： 首先以一定的概率在”Arts”、”Budgets”、”Children”、”Education”中选择一个主题 然后再以一定的概率在这个主题下选择某个单词 不断重复以上两个步骤，最终完成一篇文章 这里的两次”以一定的概率”，后面会有解释。 通过上面的分析，我们知道了文章生成过程，下来来说LDA模型《LDA数学八卦》中把文档生成过程抽象成了一个游戏，主要是为了解决刚才我们说的”以一定概率”的问题。上帝有两种类型骰子： 上面红框里面内容是说，每个doc-topic骰子是一篇文章的所有主题。 上帝在LDA模型中，玩文档生成游戏的规则是这样的： 这个文档生成规则可以看作如下过程： 首先上帝有两大坛骰子第一坛装的是doc-topic骰子，就是和所有文档相关的所有主题； 第二坛装的是topic-word骰子，就是和所有主题相关的所有单词； 开始文档生成游戏随机从topic-word坛子独立抽取K个骰子，编号为1，2，3…k 随机从doc-topic坛子抽取一个骰子，然后重复如下过程生成文档中的词: 投掷doc-topic骰子，得到一个topic编号z 投掷刚才K个骰子中选择编号为z的那个骰子，得到一个词 每次都是先生成一篇文档之后再生成第二篇，文档中每个词的生成都要投掷两次骰子，第一次投掷doc-topic骰子得到一个topic，第二次投掷topic-word骰子得到一个word，就是说生成文档中的一个词要投掷2次。如果语料中有N个词，那么上帝要抛2N次，轮换抛doc-topic和topic-word。实际上一些投掷顺序是可以交换的（这里有很多公式推导，最终得到这个顺序可以交换），我们可以等价交换这2N次投掷顺序，先抛N次doc-topic骰子，得到语料中所有词的topic，然后基于每个topic的编号，再抛N次topic-word骰子得到语料中所有word。 于是上帝的游戏规则就变成了这样： 这个过程是这样的： 随机从topic-word坛子独立抽取K个骰子，编号为1，2，3…k 随机抽取一个doc-topic骰子，然后抛出得到一个主题z，再次抽取doc-topic骰子，再抛出，得到一个主题z（注意：由于是再次抽取，所以不一定还是之前那篇文档的主题）；重复这个步骤就能得到语料中所有文档主题 从头到尾抛我们抽到的doc-topic骰子，从最开始抽到的topic-word骰子中取相应编号（在1到k中拿）的骰子抛出，得到对应的word 以面的过程是先生成了语料中所有的topic，然后生成了所有的word。在topic生成的情况下word顺序是可以交换的，即如果确定了topic k，就算和它相关的word不在同一篇文章中，也是可以交换的。 …数学家们做了假设和分析，搞懂了原理，他们决定把这些用公式表示,于是就算啊算，用到了贝叶斯、Dirichlet-Multionmial共轭结构、Gibbs-Sampling采样（一堆公式）最终… 牛X的数学家（神）得到了一个公式： 这里面z，i，k，t，v，m…只要知道都是一系列参数就行，比如文档编号、topic编号、word编号、第k个topic产生的词中word t的个数、文章数量… 这个公式右边就是p(topic|word)*p(word|topic)，概率就是doc–&gt;topic–&gt;word的路径概率： 接下来任务有两个： 这里用到了Gibbs-Sampling公式，它的意义就是在k条路径中采样，基于语料训练LDA模型，模型中参数可以基于采集到的样本进行评估（我们做这些都是为了得到上面式子的参数）。 下面是训练过程： 由这个topic-word频率矩阵我们可以计算出每一个p(word|topic)概率。 Gibbs-Sampling收敛后统计每篇文档中topic的频率分布就可以计算出p(topic|doc)的概率。(PAI平台PLDA组件有六个输出桩后面会解释) LDA的核心公式如下： P(word|doc)=p(word|topic)*p(topic|doc) 通过计算可以得到任意一个topic对应文档d中单词w出现的概率，通过这个概率不断修正我们的参数。 有了模型，接下来做的就是对于新来的文档doc(new)计算topic语义分布。 下面是具体计算过程： 迭代过程即：首先产生一个均匀分布的随机数，然后根据上式计算每个转移主题的概率，通过累积概率判断随机数落在哪个new topic下，更新参数矩阵，如此迭代直至收敛。 回到我们机器学习PAI，先看下PLDA模块的6个输出桩 输出桩1：词频，算法内部抽样后每个词在主题出现次数 输出桩2：P(单词|主题)每个主题下词的概率 输出桩3：P(主题|单词)每个单词对应各个主题的概率 输出桩4：P(文档|主题)每个主题对应各个文档的概率 输出桩5：P(主题|文档)每个文档对应主题的概率 输出桩6：P(主题)每个主题的概率，表明在整个文档中的权重 通过上面的公式推导，计算出关键的几个概率，通过贝叶斯公式这几个值都是可以算出来的。 第5个是输出桩输出结果显示的是每篇文章对应的每个主题的概率，而这个概率在上面通过p(topic|doc)已经算出。 在实验中我们设置参数topic=50，这个主题数是相对整个语料库而言的，我们最后看到的结果是这50个主题在每一篇文章上的分布情况。其它默认即可。对于默认的几个参数给予功能性的说明： 我们将文章id列和主题概率分布列，得到每个主题在每篇文章的概率分布如下图所示： 上面把文章从主题的维度表示成了一个向量。接下来就可以通过向量的距离实现聚类，从而实现文章分类。 备注：图片丢失，原文链接在评论中。","tags":[{"name":"PLDA","slug":"PLDA","permalink":"https://fuos.github.io/my-blog/tags/PLDA/"}]},{"title":"常用工具V1.0","date":"2020-06-15T14:03:15.000Z","path":"posts/16f679cd.html","text":"工作中常用的一些工具，以Windows上软件，Chrome插件和网页为主，整理记录方便自己查找。个人而言从发现一款软件，到最后能长期使用，大致经历的过程是这样的： 1.是否主流相信大家的选择。一般来说用户基数大的软件，都有不错的体验和安全性，产品维护的周期也会比较长。 2.是否免费好的产品前期都会给用户充足的体验时间。如果使用一段时间我发现这款软件确实好用而且费用又付的起，他能给我带来的收益绝不止软件价钱本身，我会选择付费。（太贵当我没说，白嫖乞丐版🤐） 3.是否开源开源≠免费，虽然很多开源软件是免费的。开源软件一般都是大神（们）用爱发电的结晶，代码透明相对安全，多人协作让功能更新和版本迭代也变得比较快，如果体验做的不错很容易成为爆款。 4.是否易用易用也是比较关键的。一般我会考虑的几点因素： 访问速度快慢：有些软件从功能开发，界面设计，到用户体验都很不错，做的很好无奈可能是由于还没开拓国内市场（慢到无法访问），导致综合体验大打折扣，所以并不是很推荐 操作简单方便：上手容易，功能明确，操作简单，界面美观，软件稳定即可（其实很难） 是否支持中文：最喜欢Simplified Chinese，第二选择是English。不过大多数软件都是开发的英文版本，后期做的国际化处理👩‍🎓 综合以上4个方面的考量，当我需要找一款工具软件时，就有了比较合理的选择方向。下面是我常用的一些工具： 📌 在线作图 | processon | excalidraw | diagrams | ASCIIFlow | 📌 代码编辑器 | Sublime Text | VS Code | 📌 笔记/TODO | Joplin | Notion | 印象笔记 | 📌 文件同步 | 坚果云 | 📌 MySQL GUI | SQLyog Community Edition | 📌 文件比较 | Diffinity | diffchecker | Meld | 📌 代码转换 | jsonschema2pojo | json.cn | JSONFormatter | URLEncoder | Base64Encoder | 📌 变量命名 | P8Z | codelf | 📌 GitHub下载 | http://g.widyun.com/ | GitZip for github | GitZip | 📌 截图贴图 | snipaste | 持续更新","tags":[{"name":"开发","slug":"开发","permalink":"https://fuos.github.io/my-blog/tags/%E5%BC%80%E5%8F%91/"}]},{"title":"GitHub Pages+Hexo+Travis CI-自动化构建的静态博客","date":"2020-06-08T13:22:55.000Z","path":"posts/aab15d5f.html","text":"博客说明📝 博客托管于GitHub Pages，使用Hexo作为博客框架，使用Travis CI完成自动构建。 博客源码放在master分支，编译生成的静态文件放在gh-pages分支。 每次写完文章后push到master上，Travis CI会自动编译出静态文件并部署到gh-pages分支。 因为有Travis CI帮助生成和部署，所以可以在Github上直接编辑文章了。 通过本博客左侧 build status链接可以看到每次构建的过程。 搭建步骤📐 环境：Windows 10 1.本地安装Node.js，Git2.在GitHub新建repository这里有两种创建方式，对应的GitHub pages地址也不一样： ①仓库名为fuos.github.io（GitHub pages）Hexo生成的静态博客文件需要放在master分支，博客地址为 fuos.github.io ②仓库名为my-blog或者其他任意名称（Project pages，本博客采用这种方式）Hexo生成的静态文件需要放在gh-pages分支，博客地址为 fuos.github.io/my-blog 3.安装Hexo本地安装和初始化Hexo，为任意名称，如my-blog： 1234$ npm install -g hexo-cli$ hexo init &lt;folder&gt;$ cd &lt;folder&gt;$ npm install 4.安装theme🎨本博客选择 indigo 作为主题，并对其中部分内容根据需要做了修改。具体安装和配置请参考官方文档：文档 | Document 这里主要修改了三个地方： ①page-about-me跳转地址 由于我创建的仓库是第二种，所以需要对themes/indigo/layout/page.ejs做相应的修改（第二行为修改后） 12&lt;a href=\"/\" class=\"avatar waves-effect waves-circle waves-light\"&gt;&lt;%- image_tag(theme.avatar) %&gt;&lt;/a&gt;&lt;a href=\"&lt;%- config.url %&gt;\" class=\"avatar waves-effect waves-circle waves-light\"&gt;&lt;%- image_tag(theme.avatar) %&gt;&lt;/a&gt; ②启用gitalk评论插件 owner为github account，repo为刚才创建的用于存放博客的repository，GitHub Application在 Settings -&gt; Developer settings -&gt; OAuth Apps申请 123456# use gitalk://github.com/gitalk/gitalkgitalk: owner: fuos repo: my-blog client_id: 'GitHub Application Client ID' client_secret: 'GitHub Application Client Secret' ③优化文章永久链接 进入my-blog安装插件： 1$ npm install hexo-abbrlink --save 修改_config.yml下permalink信息： 1234567# permalink: :year/:month/:day/:title/# permalink_defaults:permalink: posts/:abbrlink.html# abbrlink configabbrlink: alg: crc32 #support crc16(default) and crc32 rep: hex #support dec(default) and hex 5.推送分支这里将本地博客源文件推送到了master分支 1234567cd my-blog git init git remote add origin git@github.com:fuos/my-blog.gitgit add . git commit -am \"init blog\" # 推送到mastergit push -u origin master 6.使用 Travis CI 构建和部署①使用GitHub账号登陆Travis CI，在github中创建access token，在Travis CI你的repository页面Environment Variables新建环境变量，name为GH_TOKEN，Value 为刚才你在 GitHub 生成的 Token ②在my-blog下新建.travis.yml文件，添加下面的内容： 123456789101112131415161718sudo: falselanguage: node_jsnode_js: - 10 # use nodejs v10 LTScache: npmbranches: only: - master # build master branch onlyscript: - hexo generate # generate static filesdeploy: provider: pages skip-cleanup: true github-token: $GH_TOKEN keep-history: true on: branch: master local-dir: public ③修改my-blog下_config.yml中deploy部分 123456deploy: type: git # repo: https://github.com/&lt;username&gt;/&lt;project&gt; # example, https://github.com/hexojs/hexojs.github.io # Hexo静态文件默认推送到gh-pages分支 branch: gh-pages ④将修改推送到远端master 123git add .git commit -m \"add travis ci\"git push origin master 这样配置之后，Hexo已经能够自动构建和部署了，可以到travis-ci中看到Job log 之后写文章时可以按照下面的步骤新建和提交， Travis CI 会将Hexo生成的静态文件自动部署到gh-pages分支。 123456cd my-blog git checkout master hexo new \"My First Post - Test\" git add . git commit -am\"add test post\" git push 💾博客源码：https://github.com/fuos/my-blog ⚙Travis CI：https://travis-ci.org/github/fuos/my-blog","tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://fuos.github.io/my-blog/tags/Hexo/"},{"name":"Travis CI","slug":"Travis-CI","permalink":"https://fuos.github.io/my-blog/tags/Travis-CI/"}]},{"title":"My First Post - Test","date":"2020-06-07T11:10:45.000Z","path":"posts/667634fc.html","text":"测试，推送第一篇文章。Markdown 是什么？Markdown 是一种轻量级的「标记语言」，创始人为约翰·格鲁伯，用简洁的语法代替排版，目前被越来越多的知识工作者、写作爱好者、程序员或研究员广泛使用。其常用的标记符号不超过十个，相对于更为复杂的 HTML 标记语言来说，Markdown 十分的轻量，学习成本也不需要太多，且一旦熟悉这种语法规则，会有沉浸式编辑的效果。 印象笔记里 Markdown 有什么特点？插入表格 帐户类型 免费帐户 标准帐户 高级帐户 帐户流量 60M 1GB 10GB 设备数目 2台 无限制 无限制 当前价格 免费 ￥8.17/月 ￥12.33/月 插入行内代码或代码块1234567@requires_authorizationclass SomeClass: passif __name__ == '__main__': # A comment print 'hello world' 添加待办事项三只青蛙 第一只青蛙 第二只青蛙 第三只青蛙 插入链接copy from 印象笔记官网","tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://fuos.github.io/my-blog/tags/Hexo/"}]},{"title":"Hello World","date":"2020-06-07T10:50:35.000Z","path":"posts/4a17b156.html","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment 测试！最后更新时间：2020/6/12 下午5:20:00","tags":[]}]